{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "_Mah843__NLP_Homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogxGq4pYtCYB"
      },
      "source": [
        "## To submit this assignment, please solve the following problem. Then, save your notebook with the format [NETID]\\_NLP_Homework and submit via NYU Classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEgj65kktCYC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rQdcqxDtCYD"
      },
      "source": [
        "### For this assignment you must, using the text provided: \n",
        "\n",
        "1. Create a Spacy doc from the text,\n",
        "2. Print the toekn text, part of speech for each token in the doc \n",
        "3. Find and print any geographical entity mentioned in the doc\n",
        "4. Use a RegEx to find any death count mentioned in the doc\n",
        "5. Find the similarity between the entire doc and the doc \"I am happy\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IGl8eUtXtCYE"
      },
      "source": [
        "import spacy \n",
        "from spacy.lang.en import English # import the English language class\n",
        "nlp = spacy.load('en') # loading in the package we just downloaded..."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5KnfeLatCYH"
      },
      "source": [
        "# tis text is copy/pasted from a WSJ article by Brianna Abbott published 10/10/2019 at https://www.wsj.com/articles/vaping-related-lung-illnesses-jump-to-1-299-with-26-deaths-cdc-says-11570730171?mod=hp_lead_pos10\n",
        "\n",
        "text = \"\"\"\n",
        "\n",
        "The number of confirmed and probable lung-injury cases linked to vaping increased to 1,299, including 26 deaths, the federal Centers for Disease Control and Prevention said Thursday.\n",
        "\n",
        "The count of cases rose by 219 from a week ago.\n",
        "\n",
        "The cases were spread across 49 states, the District of Columbia, and the U.S. Virgin Islands, and 26 people have died. Alaska is the only state without reported cases.\n",
        "\n",
        "Connecticut, Pennsylvania, Michigan, Massachusetts, New York and Texas confirmed deaths for the first time over the past week. Georgia and California confirmed an additional death each.\n",
        "\n",
        "Among the deaths recently reported was of a 17-year-old from New York City, one of the youngest people reported to have died due to vaping-related injury so far.\n",
        "\n",
        "The CDC’s count of vaping-related deaths didn’t include one reported Wednesday by Utah’s health department. It said a person under the age of 30 years had died at home, without being hospitalized. The victim died after vaping products containing THC, the psychoactive ingredient in marijuana.\n",
        "\n",
        "If confirmed by the CDC, the Utah death would raise the total number of vaping-related fatalities across the U.S. to 27.\n",
        "\n",
        "Investigators from the Food and Drug Administration are conducting a criminal probe into the supply chain for vaping products, while health authorities investigate what is causing the vaping-related illnesses.\n",
        "\n",
        "The authorities have found that, among the 573 patients who reported their vaping habits, 76% reported using products containing THC. Many had bought the products on the black market, according to previous reports.\n",
        "\n",
        "Yet health officials say they haven’t linked any one product or substance with all of the illnesses, as only a third of the patients have reported exclusive THC use and only 13% have reported exclusive nicotine-product use.\n",
        "\n",
        "As the numbers of injured have risen, health authorities have urged people to stop using electronic cigarettes, some highlighting THC-containing products specifically.\n",
        "\n",
        "Separately, states including Massachusetts, New York and Washington have taken steps to crack down on flavored e-cigarettes, which the Trump administration has also said it would take.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvJ7kGzptCYK"
      },
      "source": [
        "## 1. Creating a Spacy doc from our text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62GKfM3stCYL"
      },
      "source": [
        "# your solution here \n",
        "doc = nlp(text) # when you process a text with the nlp object, spaCy creates a Doc object"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4fJlQtDtCYO"
      },
      "source": [
        "## 2. Finding the token text and associated part of speech for each token in our doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iOIzdFUtCYO"
      },
      "source": [
        "# your solution here\n",
        "for token in doc: # for every token in our Doc object (a token being a word or character)...\n",
        "    print(token.text) # simply print out that token "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxIuQ_QtCYR"
      },
      "source": [
        "## 3. Find and print any geographical entity mentioned in the doc\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tPGikyu-tCYR"
      },
      "source": [
        "# your solution here\n",
        "geo_ent = set()\n",
        "for ent in doc.ents: # for each entity in our Doc...\n",
        "  if ent.label_ == \"GPE\" and ent.text != 'marijuana': #For some reason, Marijuana is counted as a place (GPE)\n",
        "    geo_ent.add(ent.text) # print it alongside its label\n",
        "\n",
        "for entity in geo_ent: \n",
        "  print(entity)\n",
        "\n",
        "#GPE refers to Geographical Positionional Entity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ZALywAtCYU"
      },
      "source": [
        "## 4. Using a RegEx to find any mention of a death count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y8z606rtCYV"
      },
      "source": [
        "# your solution here \n",
        "import re\n",
        "\n",
        "expression = r'[Dd]eaths|[Dd]ied|[Ff]atalities|[Dd]eath' \n",
        "\n",
        "for match in re.finditer(expression, doc.text):\n",
        "    start, end = match.span()\n",
        "    span = doc.char_span(start, end)\n",
        "    print(\"Found match:\", span.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igkGou_ctCYY"
      },
      "source": [
        "## 5. Finding the similarity between the entire doc and the doc \"I am happy\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QdRFyLqtCYY"
      },
      "source": [
        "# your solution here\n",
        "doc1 = doc # doc 1 to be compared\n",
        "doc2 = nlp(\"I am happy\") # doc 2 to be compared\n",
        "\n",
        "print(doc1.similarity(doc2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}